{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Electrocardiograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/electrocardiograms.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x_1</th>\n",
       "      <th>x_2</th>\n",
       "      <th>x_3</th>\n",
       "      <th>x_4</th>\n",
       "      <th>x_5</th>\n",
       "      <th>x_6</th>\n",
       "      <th>x_7</th>\n",
       "      <th>x_8</th>\n",
       "      <th>x_9</th>\n",
       "      <th>x_10</th>\n",
       "      <th>...</th>\n",
       "      <th>x_179</th>\n",
       "      <th>x_180</th>\n",
       "      <th>x_181</th>\n",
       "      <th>x_182</th>\n",
       "      <th>x_183</th>\n",
       "      <th>x_184</th>\n",
       "      <th>x_185</th>\n",
       "      <th>x_186</th>\n",
       "      <th>x_187</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.041199</td>\n",
       "      <td>0.112360</td>\n",
       "      <td>0.146067</td>\n",
       "      <td>0.202247</td>\n",
       "      <td>0.322097</td>\n",
       "      <td>0.363296</td>\n",
       "      <td>0.413858</td>\n",
       "      <td>0.426966</td>\n",
       "      <td>0.485019</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.901786</td>\n",
       "      <td>0.760714</td>\n",
       "      <td>0.610714</td>\n",
       "      <td>0.466071</td>\n",
       "      <td>0.385714</td>\n",
       "      <td>0.364286</td>\n",
       "      <td>0.346429</td>\n",
       "      <td>0.314286</td>\n",
       "      <td>0.305357</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.994200</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.951276</td>\n",
       "      <td>0.903712</td>\n",
       "      <td>0.917633</td>\n",
       "      <td>0.900232</td>\n",
       "      <td>0.803944</td>\n",
       "      <td>0.656613</td>\n",
       "      <td>0.421114</td>\n",
       "      <td>0.288863</td>\n",
       "      <td>...</td>\n",
       "      <td>0.294664</td>\n",
       "      <td>0.295824</td>\n",
       "      <td>0.301624</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.984472</td>\n",
       "      <td>0.962733</td>\n",
       "      <td>0.663043</td>\n",
       "      <td>0.211180</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.032609</td>\n",
       "      <td>0.100932</td>\n",
       "      <td>0.177019</td>\n",
       "      <td>0.270186</td>\n",
       "      <td>0.313665</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.619217</td>\n",
       "      <td>0.489324</td>\n",
       "      <td>0.327402</td>\n",
       "      <td>0.110320</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.060498</td>\n",
       "      <td>0.108541</td>\n",
       "      <td>0.108541</td>\n",
       "      <td>0.145907</td>\n",
       "      <td>0.192171</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19560</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.049123</td>\n",
       "      <td>0.098246</td>\n",
       "      <td>0.108772</td>\n",
       "      <td>0.091228</td>\n",
       "      <td>0.101754</td>\n",
       "      <td>0.084211</td>\n",
       "      <td>0.105263</td>\n",
       "      <td>0.087719</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19561</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.564854</td>\n",
       "      <td>0.221757</td>\n",
       "      <td>0.202929</td>\n",
       "      <td>0.087866</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.041841</td>\n",
       "      <td>0.150628</td>\n",
       "      <td>0.240586</td>\n",
       "      <td>0.290795</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19562</th>\n",
       "      <td>0.991914</td>\n",
       "      <td>0.735849</td>\n",
       "      <td>0.215633</td>\n",
       "      <td>0.029650</td>\n",
       "      <td>0.061995</td>\n",
       "      <td>0.061995</td>\n",
       "      <td>0.016173</td>\n",
       "      <td>0.010782</td>\n",
       "      <td>0.021563</td>\n",
       "      <td>0.021563</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19563</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.839662</td>\n",
       "      <td>0.240506</td>\n",
       "      <td>0.215190</td>\n",
       "      <td>0.236287</td>\n",
       "      <td>0.198312</td>\n",
       "      <td>0.194093</td>\n",
       "      <td>0.143460</td>\n",
       "      <td>0.135021</td>\n",
       "      <td>0.071730</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19564</th>\n",
       "      <td>0.934783</td>\n",
       "      <td>0.739130</td>\n",
       "      <td>0.335404</td>\n",
       "      <td>0.093168</td>\n",
       "      <td>0.096273</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.027950</td>\n",
       "      <td>0.015528</td>\n",
       "      <td>0.009317</td>\n",
       "      <td>0.006211</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19565 rows × 188 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            x_1       x_2       x_3       x_4       x_5       x_6       x_7  \\\n",
       "0      0.000000  0.041199  0.112360  0.146067  0.202247  0.322097  0.363296   \n",
       "1      1.000000  0.901786  0.760714  0.610714  0.466071  0.385714  0.364286   \n",
       "2      0.994200  1.000000  0.951276  0.903712  0.917633  0.900232  0.803944   \n",
       "3      0.984472  0.962733  0.663043  0.211180  0.000000  0.032609  0.100932   \n",
       "4      0.619217  0.489324  0.327402  0.110320  0.000000  0.060498  0.108541   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "19560  1.000000  0.533333  0.049123  0.098246  0.108772  0.091228  0.101754   \n",
       "19561  1.000000  0.564854  0.221757  0.202929  0.087866  0.000000  0.041841   \n",
       "19562  0.991914  0.735849  0.215633  0.029650  0.061995  0.061995  0.016173   \n",
       "19563  1.000000  0.839662  0.240506  0.215190  0.236287  0.198312  0.194093   \n",
       "19564  0.934783  0.739130  0.335404  0.093168  0.096273  0.071429  0.027950   \n",
       "\n",
       "            x_8       x_9      x_10  ...     x_179     x_180     x_181  x_182  \\\n",
       "0      0.413858  0.426966  0.485019  ...  0.000000  0.000000  0.000000    0.0   \n",
       "1      0.346429  0.314286  0.305357  ...  0.000000  0.000000  0.000000    0.0   \n",
       "2      0.656613  0.421114  0.288863  ...  0.294664  0.295824  0.301624    0.0   \n",
       "3      0.177019  0.270186  0.313665  ...  0.000000  0.000000  0.000000    0.0   \n",
       "4      0.108541  0.145907  0.192171  ...  0.000000  0.000000  0.000000    0.0   \n",
       "...         ...       ...       ...  ...       ...       ...       ...    ...   \n",
       "19560  0.084211  0.105263  0.087719  ...  0.000000  0.000000  0.000000    0.0   \n",
       "19561  0.150628  0.240586  0.290795  ...  0.000000  0.000000  0.000000    0.0   \n",
       "19562  0.010782  0.021563  0.021563  ...  0.000000  0.000000  0.000000    0.0   \n",
       "19563  0.143460  0.135021  0.071730  ...  0.000000  0.000000  0.000000    0.0   \n",
       "19564  0.015528  0.009317  0.006211  ...  0.000000  0.000000  0.000000    0.0   \n",
       "\n",
       "       x_183  x_184  x_185  x_186  x_187  target  \n",
       "0        0.0    0.0    0.0    0.0    0.0       1  \n",
       "1        0.0    0.0    0.0    0.0    0.0       1  \n",
       "2        0.0    0.0    0.0    0.0    0.0       1  \n",
       "3        0.0    0.0    0.0    0.0    0.0       1  \n",
       "4        0.0    0.0    0.0    0.0    0.0       1  \n",
       "...      ...    ...    ...    ...    ...     ...  \n",
       "19560    0.0    0.0    0.0    0.0    0.0       0  \n",
       "19561    0.0    0.0    0.0    0.0    0.0       0  \n",
       "19562    0.0    0.0    0.0    0.0    0.0       0  \n",
       "19563    0.0    0.0    0.0    0.0    0.0       0  \n",
       "19564    0.0    0.0    0.0    0.0    0.0       0  \n",
       "\n",
       "[19565 rows x 188 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 19565 entries, 0 to 19564\n",
      "Columns: 188 entries, x_1 to target\n",
      "dtypes: float64(187), int64(1)\n",
      "memory usage: 28.1 MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns = \"target\")\n",
    "y = df['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fcd67f723a0>]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "at_risk_count = y[y == 1].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "healthy_count = y.shape[0] - at_risk_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.barplot( x = ['at_risk', 'healthy'],\n",
    "             y = [at_risk_count / df.target.count(), healthy_count / df.target.count()]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pretty unbalanced classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Investigating the performance of a `LogisticRegression` using cross validation to evaluate the model on the following metrics:\n",
    "- Accuracy\n",
    "- Recall\n",
    "- Precision\n",
    "- F1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "\n",
    "scoring = {'accuracy_score': 'accuracy', 'f1_score': 'f1',\n",
    "           'recall_score': 'recall', 'precision_score': 'precision'}\n",
    "\n",
    "predict = cross_validate(model, X, y, scoring = scoring)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([3.44739342, 2.52204275, 2.68585896, 2.21071029, 2.86862183]),\n",
       " 'score_time': array([0.02939153, 0.02088308, 0.04489708, 0.0232513 , 0.02261543]),\n",
       " 'test_accuracy_score': array([0.93892154, 0.93892154, 0.93994378, 0.93841043, 0.93968822]),\n",
       " 'test_f1_score': array([0.41849148, 0.46292135, 0.47191011, 0.44083527, 0.42995169]),\n",
       " 'test_recall_score': array([0.29655172, 0.35517241, 0.36206897, 0.32871972, 0.30795848]),\n",
       " 'test_precision_score': array([0.7107438 , 0.66451613, 0.67741935, 0.66901408, 0.712     ])}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9391771019677997"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct_pred_ratio = predict['test_accuracy_score'].mean()\n",
    "correct_pred_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3300942608280635"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flag_ratio = predict['test_recall_score'].mean()\n",
    "flag_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6867386740061804"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct_detection_ratio =  predict['test_precision_score'].mean()\n",
    "correct_detection_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.44482198050033483"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aggregated_metric = predict['test_f1_score'].mean()\n",
    "aggregated_metric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to the unbalance data set, it's visible how deceiving accuracy can be."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rodrigo/.pyenv/versions/3.9.5/envs/Dados/lib/python3.9/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function plot_confusion_matrix is deprecated; Function `plot_confusion_matrix` is deprecated in 1.0 and will be removed in 1.2. Use one of the class methods: ConfusionMatrixDisplay.from_predictions or ConfusionMatrixDisplay.from_estimator.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "plot_confusion_matrix(model, X_test, y_test, normalize='all')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The confusion matrix should shows that the model is influenced by the class imbalance: it predicts heartbeats to be healthy most of the time. Due to this behaviour, the model is often correct and has a high accuracy. However, it causes it to miss out on many at risk heartbeats: it has a bad recall."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "modelKNN = KNeighborsClassifier()\n",
    "\n",
    "predictKNN = cross_validate(modelKNN, X, y, scoring = scoring)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([0.02242255, 0.02496409, 0.0255959 , 0.01357794, 0.0140419 ]),\n",
       " 'score_time': array([4.19402695, 3.07795787, 3.07345176, 2.99979138, 2.5962944 ]),\n",
       " 'test_accuracy_score': array([0.98798876, 0.98441094, 0.98568873, 0.98543317, 0.98364426]),\n",
       " 'test_f1_score': array([0.91500904, 0.8892922 , 0.90070922, 0.8972973 , 0.88278388]),\n",
       " 'test_recall_score': array([0.87241379, 0.84482759, 0.87586207, 0.8615917 , 0.83391003]),\n",
       " 'test_precision_score': array([0.96197719, 0.93869732, 0.9270073 , 0.93609023, 0.93774319])}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictKNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8577210356759336"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flag_ratio_KNN = predictKNN['test_recall_score'].mean()\n",
    "flag_ratio_KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('KNN', 0.8577210356759336)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if flag_ratio - flag_ratio_KNN > 0:\n",
    "    best_model = 'LogisticRegression'\n",
    "    ratio = flag_ratio\n",
    "else:\n",
    "    best_model = 'KNN'\n",
    "    ratio = flag_ratio_KNN\n",
    "    \n",
    "best_model, ratio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The KNN classifier has a much higher recall than the LogisticRegression being better suited for the task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification Report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we know the KNN model has the best recall, let's check out its performance accross all the other classification metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99     18117\n",
      "           1       0.94      0.86      0.90      1448\n",
      "\n",
      "    accuracy                           0.99     19565\n",
      "   macro avg       0.96      0.93      0.94     19565\n",
      "weighted avg       0.99      0.99      0.99     19565\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "y_pred = cross_val_predict(modelKNN, X, y, cv=5)\n",
    "\n",
    "print(classification_report(y, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_atrisk_predictions = 0.93"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try some resampling strategies for imbalanced datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random over-sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x_1</th>\n",
       "      <th>x_2</th>\n",
       "      <th>x_3</th>\n",
       "      <th>x_4</th>\n",
       "      <th>x_5</th>\n",
       "      <th>x_6</th>\n",
       "      <th>x_7</th>\n",
       "      <th>x_8</th>\n",
       "      <th>x_9</th>\n",
       "      <th>x_10</th>\n",
       "      <th>...</th>\n",
       "      <th>x_179</th>\n",
       "      <th>x_180</th>\n",
       "      <th>x_181</th>\n",
       "      <th>x_182</th>\n",
       "      <th>x_183</th>\n",
       "      <th>x_184</th>\n",
       "      <th>x_185</th>\n",
       "      <th>x_186</th>\n",
       "      <th>x_187</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>691</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.037688</td>\n",
       "      <td>0.067839</td>\n",
       "      <td>0.085427</td>\n",
       "      <td>0.100503</td>\n",
       "      <td>0.125628</td>\n",
       "      <td>0.175879</td>\n",
       "      <td>0.218593</td>\n",
       "      <td>0.276382</td>\n",
       "      <td>0.346734</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1070</th>\n",
       "      <td>0.982143</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.991667</td>\n",
       "      <td>0.975000</td>\n",
       "      <td>0.972619</td>\n",
       "      <td>0.939286</td>\n",
       "      <td>0.832143</td>\n",
       "      <td>0.629762</td>\n",
       "      <td>0.372619</td>\n",
       "      <td>0.332143</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5148</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.632302</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.017182</td>\n",
       "      <td>0.127148</td>\n",
       "      <td>0.127148</td>\n",
       "      <td>0.082474</td>\n",
       "      <td>0.075601</td>\n",
       "      <td>0.092784</td>\n",
       "      <td>0.085911</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6616</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.902597</td>\n",
       "      <td>0.660714</td>\n",
       "      <td>0.482143</td>\n",
       "      <td>0.430195</td>\n",
       "      <td>0.392857</td>\n",
       "      <td>0.324675</td>\n",
       "      <td>0.306818</td>\n",
       "      <td>0.324675</td>\n",
       "      <td>0.318182</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11804</th>\n",
       "      <td>0.008197</td>\n",
       "      <td>0.196721</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.377049</td>\n",
       "      <td>0.372951</td>\n",
       "      <td>0.385246</td>\n",
       "      <td>0.389344</td>\n",
       "      <td>0.393443</td>\n",
       "      <td>0.360656</td>\n",
       "      <td>0.377049</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14305</th>\n",
       "      <td>0.910377</td>\n",
       "      <td>0.554245</td>\n",
       "      <td>0.318396</td>\n",
       "      <td>0.216981</td>\n",
       "      <td>0.115566</td>\n",
       "      <td>0.054245</td>\n",
       "      <td>0.009434</td>\n",
       "      <td>0.016509</td>\n",
       "      <td>0.011792</td>\n",
       "      <td>0.011792</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9268</th>\n",
       "      <td>0.261168</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.175258</td>\n",
       "      <td>0.305842</td>\n",
       "      <td>0.357388</td>\n",
       "      <td>0.371134</td>\n",
       "      <td>0.395189</td>\n",
       "      <td>0.405498</td>\n",
       "      <td>0.402062</td>\n",
       "      <td>0.395189</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7132</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.903587</td>\n",
       "      <td>0.087444</td>\n",
       "      <td>0.035874</td>\n",
       "      <td>0.136771</td>\n",
       "      <td>0.147982</td>\n",
       "      <td>0.139013</td>\n",
       "      <td>0.134529</td>\n",
       "      <td>0.125561</td>\n",
       "      <td>0.123318</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12368</th>\n",
       "      <td>0.906122</td>\n",
       "      <td>0.289796</td>\n",
       "      <td>0.134694</td>\n",
       "      <td>0.355102</td>\n",
       "      <td>0.485714</td>\n",
       "      <td>0.555102</td>\n",
       "      <td>0.534694</td>\n",
       "      <td>0.518367</td>\n",
       "      <td>0.551020</td>\n",
       "      <td>0.563265</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13764</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.835470</td>\n",
       "      <td>0.254274</td>\n",
       "      <td>0.006410</td>\n",
       "      <td>0.034188</td>\n",
       "      <td>0.100427</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.072650</td>\n",
       "      <td>0.053419</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13695 rows × 188 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            x_1       x_2       x_3       x_4       x_5       x_6       x_7  \\\n",
       "691    0.000000  0.037688  0.067839  0.085427  0.100503  0.125628  0.175879   \n",
       "1070   0.982143  1.000000  0.991667  0.975000  0.972619  0.939286  0.832143   \n",
       "5148   1.000000  0.632302  0.000000  0.017182  0.127148  0.127148  0.082474   \n",
       "6616   1.000000  0.902597  0.660714  0.482143  0.430195  0.392857  0.324675   \n",
       "11804  0.008197  0.196721  0.250000  0.377049  0.372951  0.385246  0.389344   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "14305  0.910377  0.554245  0.318396  0.216981  0.115566  0.054245  0.009434   \n",
       "9268   0.261168  0.000000  0.175258  0.305842  0.357388  0.371134  0.395189   \n",
       "7132   1.000000  0.903587  0.087444  0.035874  0.136771  0.147982  0.139013   \n",
       "12368  0.906122  0.289796  0.134694  0.355102  0.485714  0.555102  0.534694   \n",
       "13764  1.000000  0.835470  0.254274  0.006410  0.034188  0.100427  0.076923   \n",
       "\n",
       "            x_8       x_9      x_10  ...  x_179  x_180  x_181  x_182  x_183  \\\n",
       "691    0.218593  0.276382  0.346734  ...    0.0    0.0    0.0    0.0    0.0   \n",
       "1070   0.629762  0.372619  0.332143  ...    0.0    0.0    0.0    0.0    0.0   \n",
       "5148   0.075601  0.092784  0.085911  ...    0.0    0.0    0.0    0.0    0.0   \n",
       "6616   0.306818  0.324675  0.318182  ...    0.0    0.0    0.0    0.0    0.0   \n",
       "11804  0.393443  0.360656  0.377049  ...    0.0    0.0    0.0    0.0    0.0   \n",
       "...         ...       ...       ...  ...    ...    ...    ...    ...    ...   \n",
       "14305  0.016509  0.011792  0.011792  ...    0.0    0.0    0.0    0.0    0.0   \n",
       "9268   0.405498  0.402062  0.395189  ...    0.0    0.0    0.0    0.0    0.0   \n",
       "7132   0.134529  0.125561  0.123318  ...    0.0    0.0    0.0    0.0    0.0   \n",
       "12368  0.518367  0.551020  0.563265  ...    0.0    0.0    0.0    0.0    0.0   \n",
       "13764  0.072650  0.053419  0.055556  ...    0.0    0.0    0.0    0.0    0.0   \n",
       "\n",
       "       x_184  x_185  x_186  x_187  target  \n",
       "691      0.0    0.0    0.0    0.0       1  \n",
       "1070     0.0    0.0    0.0    0.0       1  \n",
       "5148     0.0    0.0    0.0    0.0       0  \n",
       "6616     0.0    0.0    0.0    0.0       0  \n",
       "11804    0.0    0.0    0.0    0.0       0  \n",
       "...      ...    ...    ...    ...     ...  \n",
       "14305    0.0    0.0    0.0    0.0       0  \n",
       "9268     0.0    0.0    0.0    0.0       0  \n",
       "7132     0.0    0.0    0.0    0.0       0  \n",
       "12368    0.0    0.0    0.0    0.0       0  \n",
       "13764    0.0    0.0    0.0    0.0       0  \n",
       "\n",
       "[13695 rows x 188 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_over = pd.concat([X_train, y_train], axis = 1)\n",
    "df_train_over"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_class_0 = df_train_over[df_train_over['target'] == 0]\n",
    "df_class_1 = df_train_over[df_train_over['target'] == 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Under-sampling might cause too much information loss, so let's jump straight to over-sampling the minority class\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_class_1_over = df_class_1.sample(df_class_0.target.count(), replace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.concat([df_class_0, df_class_1_over], axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    12657\n",
       "1    12657\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.target.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_over = df_train.drop(columns='target')\n",
    "y_train_over = df_train['target']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing the models performance on the balanced dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99      5460\n",
      "           1       0.82      0.90      0.86       410\n",
      "\n",
      "    accuracy                           0.98      5870\n",
      "   macro avg       0.91      0.94      0.92      5870\n",
      "weighted avg       0.98      0.98      0.98      5870\n",
      "\n"
     ]
    }
   ],
   "source": [
    "modelKNN = KNeighborsClassifier()\n",
    "\n",
    "modelKNN.fit(X_train_over, y_train_over)\n",
    "\n",
    "y_pred_over = modelKNN.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred_over))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.85      0.91      5460\n",
      "           1       0.30      0.85      0.44       410\n",
      "\n",
      "    accuracy                           0.85      5870\n",
      "   macro avg       0.64      0.85      0.68      5870\n",
      "weighted avg       0.94      0.85      0.88      5870\n",
      "\n"
     ]
    }
   ],
   "source": [
    "modelLG = LogisticRegression(max_iter=1000)\n",
    "\n",
    "modelLG.fit(X_train_over, y_train_over)\n",
    "\n",
    "y_pred_over = modelLG.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred_over))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Python imbalanced-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imblearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "ros = RandomOverSampler()\n",
    "\n",
    "df_ROS, y_ROS = ros.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    12657\n",
       "0    12657\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_ROS.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99      5460\n",
      "           1       0.82      0.90      0.86       410\n",
      "\n",
      "    accuracy                           0.98      5870\n",
      "   macro avg       0.91      0.94      0.92      5870\n",
      "weighted avg       0.98      0.98      0.98      5870\n",
      "\n"
     ]
    }
   ],
   "source": [
    "modelKNN = KNeighborsClassifier()\n",
    "\n",
    "modelKNN.fit(df_ROS, y_ROS)\n",
    "\n",
    "y_pred_over = modelKNN.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred_over))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.85      0.91      5460\n",
      "           1       0.30      0.86      0.45       410\n",
      "\n",
      "    accuracy                           0.85      5870\n",
      "   macro avg       0.64      0.85      0.68      5870\n",
      "weighted avg       0.94      0.85      0.88      5870\n",
      "\n"
     ]
    }
   ],
   "source": [
    "modelLG = LogisticRegression(max_iter=1000)\n",
    "\n",
    "modelLG.fit(df_ROS, y_ROS)\n",
    "\n",
    "y_pred_over = modelLG.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred_over))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tomek Links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import TomekLinks\n",
    "\n",
    "tl = TomekLinks(sampling_strategy='majority')\n",
    "\n",
    "X_tl, y_tl = tl.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      5460\n",
      "           1       0.94      0.84      0.89       410\n",
      "\n",
      "    accuracy                           0.99      5870\n",
      "   macro avg       0.97      0.92      0.94      5870\n",
      "weighted avg       0.98      0.99      0.98      5870\n",
      "\n"
     ]
    }
   ],
   "source": [
    "modelKNN = KNeighborsClassifier()\n",
    "\n",
    "modelKNN.fit(X_tl, y_tl)\n",
    "\n",
    "y_pred_over = modelKNN.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred_over))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.99      0.97      5460\n",
      "           1       0.70      0.35      0.47       410\n",
      "\n",
      "    accuracy                           0.94      5870\n",
      "   macro avg       0.83      0.67      0.72      5870\n",
      "weighted avg       0.94      0.94      0.94      5870\n",
      "\n"
     ]
    }
   ],
   "source": [
    "modelLG = LogisticRegression(max_iter=1000)\n",
    "\n",
    "modelLG.fit(X_tl, y_tl)\n",
    "\n",
    "y_pred_over = modelLG.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred_over))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "smote = SMOTE(sampling_strategy='minority')\n",
    "\n",
    "X_sm, y_sm = smote.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    12657\n",
       "0    12657\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_sm.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.99      5460\n",
      "           1       0.78      0.92      0.84       410\n",
      "\n",
      "    accuracy                           0.98      5870\n",
      "   macro avg       0.89      0.95      0.91      5870\n",
      "weighted avg       0.98      0.98      0.98      5870\n",
      "\n"
     ]
    }
   ],
   "source": [
    "modelKNN = KNeighborsClassifier()\n",
    "\n",
    "modelKNN.fit(X_sm, y_sm)\n",
    "\n",
    "y_pred_over = modelKNN.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred_over))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.85      0.91      5460\n",
      "           1       0.30      0.85      0.44       410\n",
      "\n",
      "    accuracy                           0.85      5870\n",
      "   macro avg       0.64      0.85      0.68      5870\n",
      "weighted avg       0.94      0.85      0.88      5870\n",
      "\n"
     ]
    }
   ],
   "source": [
    "modelLG = LogisticRegression(max_iter=1000)\n",
    "\n",
    "modelLG.fit(X_sm, y_sm)\n",
    "\n",
    "y_pred_over = modelLG.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred_over))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SMOTE + Tomek Links together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.combine import SMOTETomek\n",
    "\n",
    "smt = SMOTETomek(sampling_strategy='auto')\n",
    "\n",
    "X_smt, y_smt = smt.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.99      5460\n",
      "           1       0.78      0.93      0.84       410\n",
      "\n",
      "    accuracy                           0.98      5870\n",
      "   macro avg       0.88      0.95      0.92      5870\n",
      "weighted avg       0.98      0.98      0.98      5870\n",
      "\n"
     ]
    }
   ],
   "source": [
    "modelKNN = KNeighborsClassifier()\n",
    "\n",
    "modelKNN.fit(X_smt, y_smt)\n",
    "\n",
    "y_pred_over = modelKNN.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred_over))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Re-sampling techniques managed to improve model efficiency by 3% for KNN and more then 20% for the Logistic Regression model. It proves that a more balanced training dataset is vital to improving model performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble methods and model tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingClassifier, GradientBoostingClassifier,\\\n",
    "                             RandomForestClassifier, VotingClassifier\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.metrics import recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99      5460\n",
      "           1       0.93      0.93      0.93       410\n",
      "\n",
      "    accuracy                           0.99      5870\n",
      "   macro avg       0.96      0.96      0.96      5870\n",
      "weighted avg       0.99      0.99      0.99      5870\n",
      "\n"
     ]
    }
   ],
   "source": [
    "modelXGB = XGBClassifier(use_label_encoder=False, eval_metric = 'auc')\n",
    "\n",
    "modelXGB.fit(X_sm, y_sm)\n",
    "\n",
    "y_pred_over = modelXGB.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred_over))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99      5460\n",
      "           1       0.87      0.89      0.88       410\n",
      "\n",
      "    accuracy                           0.98      5870\n",
      "   macro avg       0.93      0.94      0.94      5870\n",
      "weighted avg       0.98      0.98      0.98      5870\n",
      "\n"
     ]
    }
   ],
   "source": [
    "modelBgg = BaggingClassifier()\n",
    "\n",
    "modelBgg.fit(X_sm, y_sm)\n",
    "\n",
    "y_pred_over = modelBgg.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred_over))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('knn', KNeighborsClassifier()),\n",
       "                             ('LR', LogisticRegression(max_iter=1000)),\n",
       "                             ('bgg', BaggingClassifier()),\n",
       "                             ('xgb',\n",
       "                              XGBClassifier(base_score=None, booster=None,\n",
       "                                            colsample_bylevel=None,\n",
       "                                            colsample_bynode=None,\n",
       "                                            colsample_bytree=None,\n",
       "                                            enable_categorical=False,\n",
       "                                            eval_metric='auc', gamma=None,\n",
       "                                            gpu_id=None, importance_type=None,\n",
       "                                            interaction_const...\n",
       "                                            monotone_constraints=None,\n",
       "                                            n_estimators=100, n_jobs=None,\n",
       "                                            num_parallel_tree=None,\n",
       "                                            predictor=None, random_state=None,\n",
       "                                            reg_alpha=None, reg_lambda=None,\n",
       "                                            scale_pos_weight=None,\n",
       "                                            subsample=None, tree_method=None,\n",
       "                                            use_label_encoder=False,\n",
       "                                            validate_parameters=None,\n",
       "                                            verbosity=None)),\n",
       "                             ('gbc', GradientBoostingClassifier()),\n",
       "                             ('rndfor', RandomForestClassifier())],\n",
       "                 voting='soft', weights=[1, 1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimators = [('knn', KNeighborsClassifier()),\n",
    "              ('LgR', LogisticRegression(max_iter=1000)),\n",
    "              ('bgg', BaggingClassifier()),\n",
    "              ('xgb', XGBClassifier(use_label_encoder=False, eval_metric = 'auc')),\n",
    "              ('gbc', GradientBoostingClassifier()),\n",
    "              ('rdf', RandomForestClassifier())]\n",
    "\n",
    "ensemble = VotingClassifier(\n",
    "    estimators = estimators,\n",
    "    voting = 'soft',\n",
    "    weights = [1 for i in range(len(estimators))])\n",
    "\n",
    "ensemble.fit(X_sm, y_sm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99      5460\n",
      "           1       0.92      0.95      0.93       410\n",
      "\n",
      "    accuracy                           0.99      5870\n",
      "   macro avg       0.96      0.97      0.96      5870\n",
      "weighted avg       0.99      0.99      0.99      5870\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred_over = ensemble.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred_over))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using various ensemble methods can improve model recall 1% over the best model used so far."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "288px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
